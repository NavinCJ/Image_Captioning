{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1iF67IkifOKt54yrVBAN_m1um2jESs3S8","timestamp":1692564808534}],"authorship_tag":"ABX9TyNoErPkMsH6JUbsskzOh8/4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","#References\n","#https://stackoverflow.com/questions/46910206/extracting-bounding-boxes-and-category-labels-in-ms-coco-dataset\n","#https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocotools/coco.py\n","\n","from pycocotools.coco import COCO\n","from pycocotools.cocoeval import COCOeval\n","from pycocotools import mask as maskUtils\n","\n","import tensorflow as tf\n","import collections\n","import random\n","import re\n","import numpy as np\n","import os\n","import time\n","import json\n","from glob import glob\n","from PIL import Image\n","import pickle\n","import pandas as pd\n","from google.colab import drive\n","import numpy as np\n","# Mounting the drive\n","drive.mount('/content/drive')"],"metadata":{"id":"7CalBo0-Wgig"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#littleCo = COCO('/home/r.bohare/coco_data/annotations/instances_train2014.json')"],"metadata":{"id":"NJutuxRfWx3V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download caption annotation files\n","annotation_folder = '/annotations/'\n","if not os.path.exists(os.path.abspath('.') + annotation_folder):\n","  annotation_zip = tf.keras.utils.get_file('captions.zip',\n","                                          cache_subdir=os.path.abspath('.'),\n","                                          origin = 'http://images.cocodataset.org/annotations/annotations_trainval2014.zip',\n","                                          extract = True)\n","  annotation_file = os.path.dirname(annotation_zip)+'/annotations/captions_train2014.json'\n","  instances_file = os.path.dirname(annotation_zip)+'/annotations/instances_train2014.json'\n","  os.remove(annotation_zip)"],"metadata":{"id":"ecRQe5mnaI46"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["########################Use Pycocotools################################\n","from pycocotools.coco import COCO\n","from pycocotools.cocoeval import COCOeval\n","from pycocotools import mask as maskUtils\n","\n","littleCo = COCO(instances_file)\n","\n"],"metadata":{"id":"gRmMEHTCwa0c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["__BACKPACK_CATEGORY__ = 27 #eg; 27 is backpack\n","bag_img_ids = littleCo.getImgIds(catIds=[__BACKPACK_CATEGORY__])  #3924\n","bag_imgs = littleCo.loadImgs(ids=bag_img_ids)\n","bag_img_names = [image['file_name'] for image in bag_imgs]\n","\n","prefix_str = '/content/train2014/'\n","# Append suffix / prefix to strings in list\n","final_bag_img_names = [prefix_str + sub for sub in bag_img_names]\n","print(\"FINAL Bag Images:\", len(final_bag_img_names), final_bag_img_names[:2])\n","\n","train_image_paths = final_bag_img_names\n","print(len(train_image_paths))\n","\n","########################Use Pycocotools################################"],"metadata":{"id":"g3iP3tqlwoNV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(annotation_file, 'r') as f:\n","  annotations = json.load(f)\n","\n","# Group all captions together having the same image ID.  DEFAULT DICT CREATES KEY IF IT DOES NOT EXIST!\n","# So this will have IMAGE PATH as KEY and an ARRAY OF CAPTIONS.\n","image_path_to_caption = collections.defaultdict(list)\n","\n","for val in annotations['annotations']:\n","  caption = f\"{val['caption']}\"\n","  image_path = '/content/train2014/' + 'COCO_train2014_' + '%012d.jpg' % (val['image_id'])\n","  image_path_to_caption[image_path].append(caption)\n","\n","\n","full_image_ids = []\n","full_image_paths = []\n","full_captions = []\n","for index, image_path in enumerate(train_image_paths):\n","  caption_list = image_path_to_caption[image_path]\n","  full_captions.extend(caption_list)   #extend IS adding one list to another list.\n","  full_image_paths.extend([image_path] * len(caption_list))  #ADD IMAGE PATH THAT MANY TIMES DEPENDING UPON HOW MANY CAPTIONS WAS AVAILABLE FOR THAT IMAGE\n","  full_image_ids.extend([bag_img_ids[index]] * len(caption_list))\n","\n"],"metadata":{"id":"-k5vRqxF1usR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.DataFrame(full_image_ids, columns=['Image_Id'])\n","df[\"Images_Path\"] = full_image_paths\n","df[\"Caption\"] = full_captions\n","df.to_csv('/content/drive/My Drive/Colab Notebooks/_IMAGE CAPTIONING/BACKPACK_IMAGES_CAPTIONS.csv', index=False)"],"metadata":{"id":"XHjtM1Hz47x6"},"execution_count":null,"outputs":[]}]}